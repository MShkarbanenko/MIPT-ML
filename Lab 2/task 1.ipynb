{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шкарбаненко Михаил, Б05-907"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1. Распознавания именованных сущностей на основе fasttext\n",
    "\n",
    "Построить модель расспознавания именованных сущностей на русском языке. В качестве данных использовать выборку NERUS (NER).\n",
    "\n",
    "* В качестве векторного представления токенов использовать fasttext модель;\n",
    "* В качестве модели использовать модель LSTM;\n",
    "* Архитектуру LSTM можно выбрать произвольным образом;\n",
    "* Весь процесс обучения должен быть визуализирован в tensorboard (метрики качества и пример предсказания)\n",
    "\n",
    "P.S. Выборку можно взять из [github](https://github.com/natasha/nerus).\n",
    "\n",
    "P.S.S. Для экономинии памяти компютера предлагается воспользоваться сжатием модели fasttext с 300-мерного к 100-мерному (на колаб не хватит оперативки на сжатие до 100-мерного вектора, поэтому работайте сразу с 300-мерными в VEC формате). А также использовать выполнить переопределения модели fasttext в VEC модель (см. sem-17)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовительная часть"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import gridspec\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from itertools import islice\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import dvc.api\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from nerus import load_nerus\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Девайс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps') if torch.backends.mps.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fasttext.FastText._FastText at 0x2b3a1bb80>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = fasttext.load_model('cc.ru.300.bin')\n",
    "fasttext.util.reduce_model(ft, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_nerus('nerus_lenta.conllu.gz')\n",
    "\n",
    "tokens = ft.get_words()\n",
    "tokens =  ['<PAD>', '<UNK>'] + tokens\n",
    "token_ids = defaultdict(lambda: 1, {token: idx for idx, token in enumerate(tokens)})\n",
    "\n",
    "tags = ['<PAD>', '<UNK>', 'B-LOC', 'B-ORG', 'B-PER', 'I-LOC', 'I-ORG', 'I-PER', 'O']\n",
    "tag_ids = defaultdict(lambda: 1, {tag: idx for idx, tag in enumerate(tags)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sents_tokens, self.sents_tags = [], []\n",
    "        for tokens, tags in tqdm(data, total=size):\n",
    "            tokens_idxs = list(map(token_ids.__getitem__, tokens))    \n",
    "            tags_idxs = list(map(tag_ids.__getitem__, tags))\n",
    "            self.sents_tokens.append(tokens_idxs)\n",
    "            self.sents_tags.append(tags_idxs)\n",
    "                \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.sents_tokens[idx]),\n",
    "                torch.tensor(self.sents_tags[idx]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sents_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(docs):\n",
    "    for doc in docs:\n",
    "        for sent in doc.sents:\n",
    "            yield zip(*[(t.text, t.tag) for t in sent.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e784f5117a4bbfa1732c4fd0becca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470d2947bd9b45d3a739151c59d06945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_size, test_data_size = 50000, 1000\n",
    "train_data = islice(data_generator(docs), train_data_size)\n",
    "test_data = islice(data_generator(docs), test_data_size)\n",
    "train_dataset = CustomDataset(train_data, train_data_size)\n",
    "test_dataset = CustomDataset(test_data, test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([  8898,   2244,   5937, 195560,  99130,   5687,     33,    919,  13907,\n",
      "             5,   7327,      3]), tensor([8, 8, 2, 4, 7, 8, 8, 8, 8, 8, 8, 8]))\n",
      "(tensor([90090,    19, 17720,  1343,  1741, 95614,  5604,     2,     5,  2469,\n",
      "         4435,    98, 42685,   545,  3638, 36269,    25,  7959,     2,  1029,\n",
      "         4033,   292,     3]), tensor([8, 8, 8, 8, 4, 7, 8, 8, 8, 8, 8, 2, 8, 8, 8, 8, 8, 8, 8, 8, 3, 6, 8]))\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0])\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    sents_tokens, sents_tags = zip(*batch)\n",
    "    new_sents_tokens = pad_sequence(sents_tokens, batch_first=True, padding_value=0)\n",
    "    new_sents_tags = pad_sequence(sents_tags, batch_first=True, padding_value=0)\n",
    "    return new_sents_tokens, new_sents_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(tokens):\n",
    "    embedding_matrix = []\n",
    "    for token in tqdm(tokens):\n",
    "        v = ft.get_word_vector(token)\n",
    "        embedding_matrix.append(v)\n",
    "    embedding_matrix = np.stack(embedding_matrix)\n",
    "    embedding_matrix = torch.FloatTensor(embedding_matrix)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Модель"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Архитектура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def __init__(self, embedding_matrix, output_dim, hidden_dim, \n",
    "                 num_layers, p, bidirectional=False):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "\n",
    "        \n",
    "        vocab_dim, embedding_dim = embedding_matrix.shape\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_dim, embedding_dim=embedding_dim)\n",
    "        self.embedding.weight.data.copy_(embedding_matrix)\n",
    "        for param in self.embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, num_layers,\n",
    "                               bidirectional=bidirectional,\n",
    "                               batch_first=True, dropout=p)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        embedding = self.embedding(input)\n",
    "        encoded, _ = self.encoder(embedding)\n",
    "        return self.linear(encoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Тренер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, \n",
    "                 logdir,\n",
    "                 delimeter, \n",
    "                 loaders,\n",
    "                 modelcls,\n",
    "                 loss,\n",
    "                 lr,\n",
    "                 **model_args):\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model = modelcls(**model_args).to(self.device)\n",
    "        self.loss = loss\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.logger = SummaryWriter(logdir)\n",
    "        self.delimeter = delimeter\n",
    "        self.trainloader, self.testloader = loaders\n",
    "        self.steps = 0\n",
    "\n",
    "        \n",
    "    def _calc_loss(self, batch):\n",
    "        toks, tags = [el.to(self.device) for el in batch]\n",
    "        \n",
    "        outputs = self.model(toks)\n",
    "        (outputs.shape, tags.shape)\n",
    "        \n",
    "        return self.loss(outputs.transpose(1, -1), tags)\n",
    "\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        self.model.zero_grad()\n",
    "        self.model.train()\n",
    "        \n",
    "        loss = self._calc_loss(batch)\n",
    "    \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.steps += 1\n",
    "\n",
    "        return loss.cpu().item()\n",
    "\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in self.trainloader:\n",
    "            local_loss = self.train_step(batch)\n",
    "            self.logger.add_scalar('train_loss', local_loss, self.steps)\n",
    "\n",
    "            if self.steps % self.delimeter == 0:\n",
    "                test_loss = self.test_epoch()\n",
    "                self.logger.add_scalar('test_loss', test_loss, self.steps)\n",
    "\n",
    "            epoch_loss += local_loss\n",
    "        \n",
    "        return epoch_loss/len(self.trainloader)\n",
    "\n",
    "    \n",
    "    def test_epoch(self, verbose=False):\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_loss = 0\n",
    "\n",
    "            pred = []\n",
    "            true = []\n",
    "            for batch in self.testloader:\n",
    "                local_loss = self._calc_loss(batch)\n",
    "                avg_loss += local_loss\n",
    "                \n",
    "                x_batch = batch[0].to(device)\n",
    "                with torch.no_grad():\n",
    "                    output = self.model(x_batch)\n",
    "\n",
    "                pred.extend(torch.argmax(output, dim=-1).cpu().numpy().flatten())\n",
    "                true.extend(batch[-1].cpu().numpy().flatten())\n",
    "\n",
    "            report = classification_report(true, pred, zero_division=0, labels=range(1, len(tag_ids)))\n",
    "            \n",
    "            if verbose:\n",
    "                print(report)\n",
    "            else:\n",
    "                self.logger.add_text('Report/Test', report, self.steps)\n",
    "            \n",
    "        return avg_loss / len(self.testloader)\n",
    "    \n",
    "    def train(self, n_epochs):\n",
    "        for it in tqdm(range(n_epochs)):\n",
    "            epoch_loss = self.train_epoch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b55e7f823174405b687a43a41af3f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_config = {\n",
    "    'embedding_matrix': get_embedding_matrix(tokens),\n",
    "    'output_dim': len(tag_ids),\n",
    "    'hidden_dim': 128,\n",
    "    'num_layers': 3,\n",
    "    'p': 0.5\n",
    "}\n",
    "\n",
    "trainer = Trainer(\n",
    "    'logs', 100,\n",
    "    (train_dataloader, test_dataloader),\n",
    "    RNNClassifier, torch.nn.CrossEntropyLoss(ignore_index=0),\n",
    "    lr=1e-3, **model_config\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели до обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00     447.0\n",
      "           3       0.00      0.00      0.00     386.0\n",
      "           4       0.00      0.00      0.00     347.0\n",
      "           5       0.00      0.00      0.00      55.0\n",
      "           6       0.00      0.00      0.00     289.0\n",
      "           7       0.00      0.00      0.00     215.0\n",
      "           8       0.00      0.00      0.00   15797.0\n",
      "\n",
      "   micro avg       0.00      0.00      0.00   17536.0\n",
      "   macro avg       0.00      0.00      0.00   17536.0\n",
      "weighted avg       0.00      0.00      0.00   17536.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.1861)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test_epoch(verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели после обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193af5a30964480e893224269929ffe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.86      0.96      0.91       447\n",
      "           3       0.52      0.83      0.64       386\n",
      "           4       0.93      0.86      0.89       347\n",
      "           5       0.81      0.87      0.84        55\n",
      "           6       0.44      0.78      0.56       289\n",
      "           7       0.86      0.96      0.91       215\n",
      "           8       0.39      0.99      0.56     15797\n",
      "\n",
      "   micro avg       0.40      0.98      0.57     17536\n",
      "   macro avg       0.60      0.78      0.66     17536\n",
      "weighted avg       0.42      0.98      0.58     17536\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0563)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test_epoch(verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоги"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Была построена модель для распознавания именнованных сущностей в тексте на основе LSTM. В качестве эмбеддинг-энкодера использовался предобученный fasttext. Параметры модели:\n",
    "\n",
    "* Размерность эмбеддинг матрицы: 2 000 000 x 100\n",
    "* Количество классов: 7\n",
    "* Размерность скрытого вектора LSTM: 128\n",
    "* Количество слоев LSTM: 3\n",
    "* Вероятность droput: 0.5\n",
    "\n",
    "Модель показала довольно неплохой перфоманс, несмотря на дизбаланс классов: $\\{preision, recall, f1-score\\}_{weighted} = \\{42\\%, 98\\%, 58\\%\\}$.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
